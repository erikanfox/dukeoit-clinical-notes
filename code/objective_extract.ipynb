{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes=pd.read_csv(\"~/desktop/capstone_repo/data/fake_notes_extracted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to help with detection\n",
    "\n",
    "def getMatches(col): \n",
    "    ''' creates list of regex matches and converts to dictionary'''\n",
    "    l=[]\n",
    "    for match in re.finditer(pattern, col):\n",
    "        l.append(match)\n",
    "    # sample l: [<re.Match object; span=(126, 152), match='History of Present Illness'>,\n",
    "    #  <re.Match object; span=(154, 169), match='FIRST_NAME_FULL'>]\n",
    "    return getMatchDict(l) # use following function to convert to dictionary\n",
    "    # l as a dictionary: {History of Present Illness':126,'FIRST_NAME_FULL':154}\n",
    "\n",
    "def getMatchDict(col):\n",
    "    '''convert list of matches to clean dictionary'''\n",
    "    if col is None:\n",
    "        return None\n",
    "    else:\n",
    "        dic=[]\n",
    "        for i in col:\n",
    "            dic.append((i[0],i.start()))\n",
    "        return dic\n",
    "\n",
    "\n",
    "def getLastItem(col):\n",
    "    return col[-1]\n",
    "\n",
    "def getEnd(col):\n",
    "    return col[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up 'Objective'\n",
    "\n",
    "The 'Objective' section in a SOAP note consists of several subsections that we will seperate in this notebook.\n",
    "Subsections: vitals, physical exam constitutional, other (labs and medications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Seperate the 'other' (labs, medications, etc) section'''\n",
    "\n",
    "pattern=r'Medication Administration Report|DATA|LABS:|Intake and Output last 24 hours|Lab Review|Laboratory Results|LABS REVIEWED:|Pertinent Diagnostic Studies|Labs/Studies:|Recent Labs|SCHEDULED MEDICATIONS|Immunization History|Scheduled Meds:|Current Medications:|Data:|Medications:|Lab Review:|Scheduled Medications|Lab Results|Labs and Imaging|Relevant Labs and Imaging:|Medications|Pertinent Labs and Studies:|Labs and Studies:|Labs:|Laboratory Studies:'\n",
    "notes['contains_labs'] = notes['Objective'].str.contains(pattern) \n",
    "print(\"percent of notes that have a lab/medication section in objective: \"+str(notes['contains_labs'].sum()/notes.shape[0]))\n",
    "notes['labs']= notes['Objective'].apply(lambda x:getMatches(x))\n",
    "\n",
    "# create two temporary dataframes: one with notes that have this section\n",
    "# and one with notes that are missing this section\n",
    "#this is because we want to do different things with each group\n",
    "df2=notes[notes.contains_labs].copy()\n",
    "df3=notes[notes.contains_labs==False].copy()\n",
    "\n",
    "# if the note has labs/medications, use match to extract it\n",
    "df2[\"Objective_PhysExam\"]=df2.apply(lambda row: row.Objective[0:row.labs[0][1]], axis=1)\n",
    "df2[\"Objective_other\"]=df2.apply(lambda row: row.Objective[row.labs[0][1]:], axis=1)\n",
    "\n",
    "# if the note has no labs/medications info, set feature to nan\n",
    "df3[\"Objective_PhysExam\"]=df3.Objective\n",
    "df3[\"Objective_other\"]=np.nan\n",
    "\n",
    "#concat temp dataframes back together\n",
    "notes=pd.concat([df2,df3])\n",
    "notes=notes[[\"note_text\",\"type\",\"Subjective\",\"Objective\",\"Objective_PhysExam\",\"Objective_other\",\"Assessment\",\"Plan\",\"diags\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look for 'Physical Exam Constitutional' next.\n",
    "This section is the most difficult to find, as sometimes it is called plainly \"Physical Exam\", which is a bad keyword for us to use, as this same keyword also sometimes indicates the vitals section.\n",
    "\n",
    "We will look for this section with two different methods and then append them together later.\n",
    "\n",
    "Method 1: find all instances of 'Physical Exam' in the text that are NOT followed by any of a list of additional keywords that indicate that the following section is vitals.\n",
    "\n",
    "Method 2: Look for additional headers of physical exam constitutional, such as \"general appearance\", \"constitutional\", \"GA\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Seperate out Physical Exam Constitutional, method 1'''\n",
    "\n",
    "# The following pattern looks for physical exam when NOT followed by Vitals, Temp, Current Vitals, etc, or PE.\n",
    "pattern=r'(Physical Exam)(?!((:?)( *)(,?)Vital|(:?)( *)Temp|s and NIH Stroke Scales|(:?)( *)Current Vital))|PE |(PHYSICAL EXAM)(?!((:?)( *)(,?)Vital|(:?)( *)Temp|s and NIH Stroke Scales|(:?)( *)Current Vital))'\n",
    "notes['contains_pe'] = notes['Objective_PhysExam'].str.contains(pattern) \n",
    "\n",
    "# create two temp dataframes\n",
    "df2=notes[notes[\"contains_pe\"]==True].reset_index()\n",
    "df=notes[notes[\"contains_pe\"]==False].reset_index()\n",
    "\n",
    "# if PE is found, extract it\n",
    "df2['PE']= df2['Objective_PhysExam'].apply(lambda x:getMatches(x))\n",
    "df2[\"Objective_PE\"]=df2.apply(lambda row: row.Objective_PhysExam[row.PE[-1][1]:] if row.PE[-1][1]>0 else \" \", axis=1)\n",
    "df2[\"Objective_PhysExam\"]=df2.apply(lambda row: row.Objective_PhysExam[0:row.PE[-1][1]]if row.PE[-1][1]>0 else row.Objective_PhysExam, axis=1)\n",
    "df2=df2[[\"type\",\"note_text\",\"Subjective\",\"Objective\",\"Objective_PhysExam\",\"Objective_PE\",\"Objective_other\",\"Assessment\",\"Plan\",\"diags\",\"PE\"]]\n",
    "\n",
    "# if PE is not found, set it to empty string\n",
    "df[\"Objective_PE\"]=\" \"\n",
    "df[\"PE\"]=\" \"\n",
    "df=df[[\"type\",\"note_text\",\"Subjective\",\"Objective\",\"Objective_PhysExam\",\"Objective_PE\",\"Objective_other\",\"Assessment\",\"Plan\",\"diags\",\"PE\"]]\n",
    "\n",
    "#combine temps back into notes\n",
    "notes=pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a handful of the notes have the vitals section after constitutional,\n",
    "#  so we can handle that here real quick \n",
    "# (all of these vital sections are labeled with 'Current vitals')\n",
    "\n",
    "pattern=r'Current Vitals'\n",
    "notes['contains_v'] = notes['Objective_PE'].str.contains(pattern) \n",
    "notes['v']= notes['Objective_PE'].apply(lambda x:getMatches(x))\n",
    "\n",
    "# create temp dataframes\n",
    "df=notes[notes[\"contains_v\"]].copy()\n",
    "df2=notes[notes[\"contains_v\"]==False].copy()\n",
    "\n",
    "# extract or set to empty string\n",
    "df[\"Objective_vitals\"]=df.apply(lambda row: row.Objective_PE[row.v[0][1]:], axis=1)\n",
    "df[\"Objective_PE\"]=df.apply(lambda row: row.Objective_PE[0:row.v[0][1]], axis=1)\n",
    "df2[\"Objective_vitals\"]=\"\"\n",
    "\n",
    "\n",
    "#combine temps back into notes\n",
    "notes=pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''handle cases where the vitals section is missing'''\n",
    "\n",
    "# create two temp dataframes, one with notes where we found vitals\n",
    "# one with notes where we did not find vitals\n",
    "novit=notes[notes[\"Objective_vitals\"]==\"\"]\n",
    "vit=notes[notes[\"Objective_vitals\"]!=\"\"]\n",
    "\n",
    "\n",
    "## We did this because we want to work with \n",
    "# the notes where we did not find vitals\n",
    "\n",
    "# create two more temp dataframes out of the \"no vitals\" notes,\n",
    "#  one where physical exam is found and one where its not\n",
    "dfpe=novit[novit[\"Objective_PE\"]!=\" \"].copy()\n",
    "df=novit[novit[\"Objective_PE\"]==\" \"].copy()\n",
    "\n",
    "# if we found physical exam, in a note where we didnt find vitals,\n",
    "# we can infer the last match of 'physical exam' is labeling vitals section\n",
    "# assign content after final match of physical exam to vitals feature\n",
    "dfpe[\"PE_item\"]=dfpe[\"PE\"].apply(lambda x: getLastItem(x))\n",
    "dfpe[\"PE_start\"]=dfpe[\"PE_item\"].apply(lambda x: getEnd(x))\n",
    "dfpe[\"Objective_vitals\"]=dfpe.apply(lambda row: row.Objective_PhysExam[0:row.PE_start], axis=1)\n",
    "\n",
    "\n",
    "# some of the notes in the \"no vitals\" temp dataframe are no longer missing vitals,\n",
    "# so we concat them back together and reseperate to update\n",
    "novit=pd.concat([dfpe,df])\n",
    "notes=pd.concat([vit,novit])\n",
    "novit=notes[notes[\"Objective_vitals\"]==\"\"].copy()\n",
    "vit=notes[notes[\"Objective_vitals\"]!=\"\"].copy()\n",
    "\n",
    "\n",
    "# if we find \"Temp\" in the \"no vitals\" dataframe now, it means that the entire\n",
    "# section is just vitals. So we assign it accordingly.\n",
    "pattern=r'Temp(:| )'\n",
    "novit['contains_temp'] = novit['Objective_PhysExam'].str.contains(pattern) \n",
    "novit[\"Objective_vitals\"]=np.where(novit.contains_temp,novit.Objective_PhysExam,\"\")\n",
    "notes=pd.concat([vit,novit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Seperate out Physical Exam Constitutional, method 2'''\n",
    "\n",
    "pattern=r'Gen:|General(:| |.)|GEN(:| )|Neurologic Exam: |Intake/Output Summary \\(Last 24 hours\\)|INITIAL Exam \\(very first encounter\\)|CONST:|Constitutional:|Lines, drains, airways:|Mental Status Exam|GA:|PHYSICAL EXAM:  Constitutional:|Exam:( *)GE:|MENTAL STATUS:|Appearance:|GENERAL(:| )|CONSTITUTIONAL:|GENERAL APPEARANCE:?|Exam:( *)Cardiac=|Exam: Heart|Musculoskeletal Exam|ENT: '\n",
    "notes['contains_gen'] = notes['Objective_PhysExam'].str.contains(pattern) \n",
    "notes['gen']= notes['Objective_PhysExam'].apply(lambda x:getMatches(x))\n",
    "\n",
    "# create temp dataframes, one where we found gen keyword and one where we did not\n",
    "df=notes[notes[\"contains_gen\"]].copy()\n",
    "df2=notes[notes[\"contains_gen\"]==False].copy()\n",
    "\n",
    "# if we found gen, extract it\n",
    "df[\"Objective_gen\"]=df.apply(lambda row: row.Objective_PhysExam[row.gen[0][1]:], axis=1)\n",
    "df[\"Objective_vitals\"]=df.apply(lambda row: row.Objective_PhysExam[0:row.gen[0][1]], axis=1)\n",
    "df=df[[\"type\",\"note_text\",\"Subjective\",\"Objective\",\"Objective_PhysExam\",\"Objective_PE\",\"Objective_vitals\",\"Objective_gen\",\"Objective_other\",\"Assessment\",\"Plan\",\"diags\",\"PE\",\"gen\"]]\n",
    "\n",
    "# if we did not find, set to empty string\n",
    "df2[\"Objective_gen\"]=\"\"\n",
    "df2=df2.drop(columns=[\"contains_gen\",\"contains_v\"])\n",
    "\n",
    "#combine temp dataframes back into notes\n",
    "notes=pd.concat([df,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create physical exam constitutional feature, combining the two methods\n",
    "notes[\"Objective_const\"] = notes[\"Objective_PE\"] + notes[\"Objective_gen\"]\n",
    "\n",
    "#edit notes to only have the columns we want\n",
    "notes=notes[[\"type\",\"note_text\",\"Subjective\",\"Objective\",\"Objective_vitals\",\"Objective_const\",\"Objective_other\",\"Assessment\",\"Plan\",\"diags\"]]\n",
    "notes=notes[notes[\"Objective_const\"]!=\" \"].reset_index()\n",
    "notes=notes.drop(columns=[\"index\"])\n",
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes.to_csv(\"~/projects/PACE - MIDS Student Portfolio Capstone/data/notes_extracted_obj.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
